{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biography Comparison Module\n",
    "## Introduction\n",
    "The aim of this module is to provide the necessary training and comparison functions for a biography module. It is supposed to establish the similarity between two users' bios, while taking into account the rarity of certain embeddings, which are topics or terms that can be represented by various words.\n",
    "\n",
    "## Architecture and Thought Process\n",
    "While the most straight forward way of comparing multiple bios is to use [Sentence-BERT](https://towardsdatascience.com/an-intuitive-explanation-of-sentence-bert-1984d144a868), this does not take into account the rarity of certain topics. For example, if a user has a bio that contains the word \"gym\", this word is not very rare, and therefore, it does not make sense that the presence of this embedding in both bios to have the same weight as the word \"theater\", which is a much more niche interest. We need to take into account the rarity of certain topics, and therefore, we need to use a different approach.\n",
    "\n",
    "![Sentence-BERT Architecture](https://miro.medium.com/max/1124/1*6gjaA_TqojVTABHJPNRMng.jpeg)\n",
    "\n",
    "^ This is the architecture of Sentence-BERT for reference.\n",
    "\n",
    "We can use almost the same architecture but replace the `cosine-similarity` function with a weighted cosinge similarity function where the weight for each embedding is proportional to its rarity. This would be a potential formula for the weighted cosine similarity function:\n",
    "$$\\frac{\\sum_{i}{w_i u_i v_i}}{\\sqrt{\\sum_{i}w_i u_i^2}\\sqrt{\\sum_{i}w_i v_i^2}}$$\n",
    "Where $w_i$ is the weight of the $i^{th}$ embedding, $u_i$ is the $i^{th}$ embedding of the first bio, and $v_i$ is the $i^{th}$ embedding of the second bio.\n",
    "\n",
    "### Why not GloVe?\n",
    "GloVe is a system for generatting a vector / embedding list for a sentence. The following question could be raised: why would we use BERT for generating sentence embeddings if we are not going to use use our own comparison function instead of BERT's native function. GloVe segments sentences using traditional word-like tokens, while BERT learns the uses finer grained segmenetation and learns \"[learns its custom word-piece embeddings jointly with the entire model](https://datascience.stackexchange.com/questions/73189/does-bert-use-glove#:~:text=BERT%20cannot%20use%20GloVe%20embeddings,subword%20units%20called%20word%2Dpieces.)\". This could be useful in the case of school specific lingo not encoded into the GloVe model but that could be trained into BERT (<span style=\"color:orange\">fastText could be explored as an alternative since it has similar learning capabilities</span>).\n",
    "\n",
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== User: 0 =====\n",
      "Matched with 3 with score 1.0246800854802132\n",
      "Matched with 6 with score 1.0028615249320865\n",
      "Matched with 2 with score 0.9918926283717155\n",
      "Matched with 7 with score 0.9746066741645336\n",
      "Matched with 1 with score 0.9636695198714733\n",
      "Matched with 5 with score 0.8689927160739899\n",
      "Matched with 4 with score 0.3212115168571472\n",
      "===== User: 1 =====\n",
      "Matched with 2 with score 1.0367830768227577\n",
      "Matched with 5 with score 1.032725878059864\n",
      "Matched with 6 with score 1.0136096188798547\n",
      "Matched with 3 with score 0.9907048298045993\n",
      "Matched with 7 with score 0.9883512947708368\n",
      "Matched with 0 with score 0.9636695198714733\n",
      "Matched with 4 with score 0.7895365059375763\n",
      "===== User: 2 =====\n",
      "Matched with 1 with score 1.0367830768227577\n",
      "Matched with 0 with score 0.9918926283717155\n",
      "Matched with 4 with score 0.9769552703946829\n",
      "Matched with 5 with score 0.9641275219619274\n",
      "Matched with 3 with score 0.7559625208377838\n",
      "Matched with 6 with score 0.7439515888690948\n",
      "Matched with 7 with score 0.49044984579086304\n",
      "===== User: 3 =====\n",
      "Matched with 5 with score 1.050190456211567\n",
      "Matched with 0 with score 1.0246800854802132\n",
      "Matched with 1 with score 0.9907048298045993\n",
      "Matched with 4 with score 0.9724562428891659\n",
      "Matched with 7 with score 0.8030699640512466\n",
      "Matched with 2 with score 0.7559625208377838\n",
      "Matched with 6 with score 0.10609626770019531\n",
      "===== User: 4 =====\n",
      "Matched with 2 with score 0.9769552703946829\n",
      "Matched with 3 with score 0.9724562428891659\n",
      "Matched with 6 with score 0.9408878348767757\n",
      "Matched with 5 with score 0.9370759949088097\n",
      "Matched with 7 with score 0.9100167751312256\n",
      "Matched with 1 with score 0.7895365059375763\n",
      "Matched with 0 with score 0.3212115168571472\n",
      "===== User: 5 =====\n",
      "Matched with 6 with score 1.0509310588240623\n",
      "Matched with 3 with score 1.050190456211567\n",
      "Matched with 1 with score 1.032725878059864\n",
      "Matched with 2 with score 0.9641275219619274\n",
      "Matched with 7 with score 0.9583177268505096\n",
      "Matched with 4 with score 0.9370759949088097\n",
      "Matched with 0 with score 0.8689927160739899\n",
      "===== User: 6 =====\n",
      "Matched with 5 with score 1.0509310588240623\n",
      "Matched with 1 with score 1.0136096188798547\n",
      "Matched with 0 with score 1.0028615249320865\n",
      "Matched with 4 with score 0.9408878348767757\n",
      "Matched with 7 with score 0.8307725638151169\n",
      "Matched with 2 with score 0.7439515888690948\n",
      "Matched with 3 with score 0.10609626770019531\n",
      "===== User: 7 =====\n",
      "Matched with 1 with score 0.9883512947708368\n",
      "Matched with 0 with score 0.9746066741645336\n",
      "Matched with 5 with score 0.9583177268505096\n",
      "Matched with 4 with score 0.9100167751312256\n",
      "Matched with 6 with score 0.8307725638151169\n",
      "Matched with 3 with score 0.8030699640512466\n",
      "Matched with 2 with score 0.49044984579086304\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from scipy.spatial import distance\n",
    "\n",
    "BIOGRAPHIES = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'I love pasta',\n",
    "             'The new movie is awesome',\n",
    "             'The cat plays in the garden',\n",
    "             'A woman watches TV',\n",
    "             'The new movie is so great',\n",
    "             'Do you like pizza?']\n",
    "\n",
    "SELECTED_TOP_PER_USER = 10\n",
    "\n",
    "class BioClassifier:\n",
    "    def __init__(self):\n",
    "        # self.model = SentenceTransformer('all-mpnet-base-v2') # Best perfomring sentence embedding model\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2') # Almost as good as all-mpnet-base-v2, but 2x faster\n",
    "        self.embedding_weights = None\n",
    "\n",
    "    # Returns a list of length len(biographies) with the embeddings of each biography\n",
    "    def encode(self, biographies):\n",
    "        return self.model.encode(biographies, convert_to_tensor=True)\n",
    "\n",
    "    def train(self, bio_embeddings):\n",
    "        self.embedding_weights = np.empty(bio_embeddings.shape[1]) # Initialize empty weights (one per embedding dimension)\n",
    "        self.embedding_weights = None\n",
    "        # TODO Calculate embedding weights\n",
    "\n",
    "    def encode_and_train(self, biographies): \n",
    "        bio_embeddings = self.encode(biographies)\n",
    "        self.train(bio_embeddings)\n",
    "        return bio_embeddings\n",
    "\n",
    "    def compare(self, bio1_embeddings, bio2_embeddings):\n",
    "        # TODO Re add training check\n",
    "        # if self.embedding_weights is None:\n",
    "        #     raise Exception('The classifier has not been trained yet')\n",
    "        return distance.cosine(bio1_embeddings, bio2_embeddings, self.embedding_weights)\n",
    "        # return util.cos_sim([bio1_embeddings], [bio2_embeddings])[0][0] #! Check why cos_sim returns different results than weighted cosine with no weights.\n",
    "    \n",
    "\n",
    "def main():\n",
    "    biographies = BIOGRAPHIES\n",
    "    classifier = BioClassifier()\n",
    "    biographies_embeddings = classifier.encode_and_train(biographies)\n",
    "\n",
    "    # Compute/find the highest similarity scores\n",
    "    pairs = []\n",
    "    for i in range(len(biographies_embeddings) - 1):\n",
    "        for j in range(i + 1, len(biographies_embeddings)):\n",
    "            score = classifier.compare(biographies_embeddings[i], biographies_embeddings[j])\n",
    "            pairs.append({'index': (i, j), 'score': score})\n",
    "    \n",
    "    # Sort the scores in decreasing order\n",
    "    selected_matches = defaultdict(lambda: [])\n",
    "    pairs = sorted(pairs, key=lambda x: x['score'], reverse=True)\n",
    "    for pair in pairs:\n",
    "        i, j = pair['index']\n",
    "        score = pair['score']\n",
    "        if len(selected_matches[i]) < SELECTED_TOP_PER_USER:\n",
    "            selected_matches[i].append({'user': j, 'score': score})\n",
    "        if len(selected_matches[j]) < SELECTED_TOP_PER_USER:\n",
    "            selected_matches[j].append({'user': i, 'score': score})\n",
    "\n",
    "    for i, matches in sorted(selected_matches.items()):\n",
    "        print(f'===== User: {i} =====')\n",
    "        for match in matches:\n",
    "            user = match['user']\n",
    "            score = match['score']\n",
    "            print(f'Matched with {user} with score {score}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b325b5bb9bcec4a326b374356a4a64a5492f094bf1e34dc74a85182709cdeda"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
